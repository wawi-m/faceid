{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images path\n",
    "img_dir = 'train_images'\n",
    "# Path to the folder containing test images\n",
    "test_img_dir = 'test_images'\n",
    "# Create a mapping from folder names to integer labels\n",
    "label_map = {'wmaathai': 1, 'others': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FaceRecognizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty lists for training images and image-labels\n",
    "faces = []\n",
    "ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Haar Cascade classifiers for frontal and side faces\n",
    "front_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "side_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to track processed face coordinates (to avoid duplicates)\n",
    "processed_faces_coordinates = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\1.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\11.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\12.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\13.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\others\\14.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\15.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\16.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\18.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\19.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\2.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\20.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\21.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\22.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\23.jpg\n",
      "Detected 2 front face(s) and 1 side face(s) in train_images\\others\\24.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\25.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\26.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\3.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\4.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\5.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\6.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\others\\7.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\8.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\9.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\1.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\10.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\11.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\12.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\13.jpg\n",
      "Detected 2 front face(s) and 1 side face(s) in train_images\\wmaathai\\14.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\15.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\16.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\17.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\18.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\19.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\2.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\20.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\21.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\22.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\23.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\24.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\wmaathai\\25.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\26.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\27.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\wmaathai\\28.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\3.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\30.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\4.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\wmaathai\\5.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\6.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\7.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\8.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\9.jpg\n"
     ]
    }
   ],
   "source": [
    "# train FaceRecognizer model\n",
    "for root, dirs, files in os.walk(img_dir):\n",
    "    for filename in files:\n",
    "    \n",
    "        # Check if the file is an image (JPG, PNG, JPEG)\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(root, filename)  # Get full image path relative to root\n",
    "        \n",
    "            # Read the image\n",
    "            img = cv2.imread(image_path)\n",
    "\n",
    "            # Skip invalid images\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {image_path}\")\n",
    "                continue\n",
    "\n",
    "            # Convert the image to grayscale (Haar cascades work with grayscale images)\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect frontal faces\n",
    "            front_faces = front_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            # Detect side faces\n",
    "            side_faces = side_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            print(f\"Detected {len(front_faces)} front face(s) and {len(side_faces)} side face(s) in {image_path}\")\n",
    "\n",
    "            #skip invalid images\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {image_path}\")\n",
    "                continue\n",
    "\n",
    "            # Combine both frontal and side faces into one list only if they are valid\n",
    "            all_faces = []\n",
    "            if len(front_faces) > 0:\n",
    "                all_faces.extend(front_faces)\n",
    "            if len(side_faces) > 0:\n",
    "                all_faces.extend(side_faces)\n",
    "            \n",
    "            # Process each detected face\n",
    "            for (x, y, w, h) in all_faces:\n",
    "                if (x, y, w, h) in processed_faces_coordinates:\n",
    "                    continue  # Skip if face already processed\n",
    "\n",
    "                processed_faces_coordinates.add((x, y, w, h))  # Add coordinates to avoid duplicate processing\n",
    "                face_region = gray_img[y:y + h, x:x + w]  # Extract face region\n",
    "\n",
    "                # Detect eyes within the detected face region\n",
    "                eyes = eye_cascade.detectMultiScale(face_region, scaleFactor=1.1, minNeighbors=3, minSize=(30, 30))\n",
    "\n",
    "                if len(eyes) > 0:  # If eyes are detected, process this face\n",
    "                    faces.append(face_region)  # Add the face to the list\n",
    "                    label = os.path.basename(root)  # Folder name as the label\n",
    "                    if label in label_map:\n",
    "                        ids.append(label_map[label])  # Add corresponding label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection\n",
    "-consider if a face is not detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Check if faces and ids are not empty before training\n",
    "if len(faces) > 0 and len(ids) > 0:\n",
    "    # Create and train the recognizer\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.train(faces, np.array(ids))  # Train the recognizer with the faces and corresponding ids\n",
    "\n",
    "    # Save the trained model\n",
    "    recognizer.save('./trained/trained_model.yml')\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "else:\n",
    "    print(\"No faces detected, model training skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(faces, np.array(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "recognizer.save('trained/trained_model.yml')\n",
    "print(\"Model trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for face recognition\n",
    "recognizer.read('trained/trained_model.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: 1.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'imshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m test_img_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(test_img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Display the image using matplotlib\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m(test_img_rgb)\n\u001b[0;32m     73\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Hide axes\u001b[39;00m\n\u001b[0;32m     74\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_image_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Title with the image name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gladys.Mwangi\\AppData\\Local\\anaconda3\\envs\\faceid_env\\Lib\\site-packages\\matplotlib\\_api\\__init__.py:218\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'imshow'"
     ]
    }
   ],
   "source": [
    "# Loop through the test images\n",
    "for test_image_name in os.listdir(test_img_dir):\n",
    "    test_image_path = os.path.join(test_img_dir, test_image_name)\n",
    "\n",
    "    test_img = cv2.imread(test_image_path)\n",
    "    if test_img is None:\n",
    "        print(f\"Failed to load image {test_image_path}\")\n",
    "        continue  # Skip invalid images\n",
    "\n",
    "    gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)  # Convert test image to grayscale for face detection\n",
    "\n",
    "    # Detect frontal and side faces\n",
    "    front_faces = front_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    side_faces = side_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Combine both frontal and side faces into one list\n",
    "    all_faces = []\n",
    "    if len(front_faces) > 0:\n",
    "        all_faces.extend(front_faces)\n",
    "    if len(side_faces) > 0:\n",
    "        all_faces.extend(side_faces)\n",
    "\n",
    "    # Variable to track if a recognized face is found\n",
    "    is_wmaathai = False\n",
    "    print(f\"Processing image: {test_image_name}\")\n",
    "\n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in all_faces:\n",
    "        face_region = gray_img[y:y + h, x:x + w]  # Extract the face region\n",
    "\n",
    "        # Detect eyes within the face region\n",
    "        eyes = eye_cascade.detectMultiScale(face_region, scaleFactor=1.1, minNeighbors=3, minSize=(30, 30))\n",
    "\n",
    "        if len(eyes) > 0:  # If eyes are detected, proceed with face recognition\n",
    "            # Recognize the face using the trained recognizer\n",
    "            label, confidence = recognizer.predict(face_region)\n",
    "\n",
    "            # Log the label and confidence for debugging\n",
    "            print(f\"  Detected face with label: {label}, confidence: {confidence}\")\n",
    "\n",
    "            # Check if the confidence value is good (low confidence means a good match)\n",
    "            if confidence < 100:  # Low confidence means a good match\n",
    "                if label == 1:\n",
    "                    is_wmaathai = True\n",
    "                    text = f\"{test_image_name}: wmaathai\"\n",
    "                    color = (0, 255, 0)  # Green text for 'wmaathai'\n",
    "                else:\n",
    "                    text = f\"{test_image_name}: not wmaathai\"\n",
    "                    color = (0, 0, 255)  # Red text for 'not wmaathai'\n",
    "            else:\n",
    "                # If the confidence is too high, mark the face as unknown\n",
    "                text = f\"{test_image_name}: unknown\"\n",
    "                color = (0, 0, 255)  # Red text for 'unknown'\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(test_img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            # Put text on the image\n",
    "            cv2.putText(test_img, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # If no faces were detected or recognized, output unknown\n",
    "    if len(all_faces) == 0:\n",
    "        print(f\"No faces detected in {test_image_name}\")\n",
    "        text = f\"{test_image_name}: unknown\"\n",
    "        color = (0, 0, 255)\n",
    "        cv2.putText(test_img, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Convert the image to RGB (from BGR, OpenCV uses BGR format)\n",
    "    test_img_rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(test_img_rgb)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.title(f\"Test Image: {test_image_name}\")  # Title with the image name\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: 1.jpg\n",
      "  Detected front face with label: 0, confidence: 98.40679446849418\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'imshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo faces detected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_image_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Display the image using matplotlib\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m(cv2\u001b[38;5;241m.\u001b[39mcvtColor(test_img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))  \u001b[38;5;66;03m# Convert BGR to RGB for correct display\u001b[39;00m\n\u001b[0;32m    105\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    106\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Hide the axis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gladys.Mwangi\\AppData\\Local\\anaconda3\\envs\\faceid_env\\Lib\\site-packages\\matplotlib\\_api\\__init__.py:218\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'imshow'"
     ]
    }
   ],
   "source": [
    "# Load the trained model for face recognition\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trained/trained_model.yml')\n",
    "\n",
    "# Initialize Haar Cascade classifiers for frontal and side faces\n",
    "front_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "side_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')\n",
    "\n",
    "# Set to track processed face coordinates (to avoid duplicates)\n",
    "processed_faces_coordinates = set()\n",
    "\n",
    "# Loop through the test images in the test_img_dir\n",
    "for test_image_name in os.listdir(test_img_dir):\n",
    "    test_image_path = os.path.join(test_img_dir, test_image_name)\n",
    "\n",
    "    # Read the test image\n",
    "    test_img = cv2.imread(test_image_path)\n",
    "    if test_img is None:\n",
    "        print(f\"Failed to load image {test_image_path}\")\n",
    "        continue  # Skip invalid images\n",
    "\n",
    "    # Convert the test image to grayscale for face detection\n",
    "    gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using both frontal and side face classifiers\n",
    "    front_faces = front_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    side_faces = side_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Variable to track if a recognized face is found\n",
    "    is_wmaathai = False\n",
    "    print(f\"Processing image: {test_image_name}\")\n",
    "\n",
    "    # Process each detected front face\n",
    "    for (x, y, w, h) in front_faces:\n",
    "        # Check if this face has already been processed (duplicate detection)\n",
    "        if (x, y, w, h) in processed_faces_coordinates:\n",
    "            continue  # Skip if face already processed\n",
    "\n",
    "        # Add the face coordinates to the set to avoid duplicate processing\n",
    "        processed_faces_coordinates.add((x, y, w, h))\n",
    "\n",
    "        # Extract face region from grayscale image\n",
    "        face_region = gray_img[y:y + h, x:x + w]\n",
    "\n",
    "        # Recognize the face using the trained recognizer\n",
    "        label, confidence = recognizer.predict(face_region)\n",
    "\n",
    "        # Log the label and confidence for debugging\n",
    "        print(f\"  Detected front face with label: {label}, confidence: {confidence}\")\n",
    "\n",
    "        # Adjusted confidence check for wmaathai or others\n",
    "        if confidence < 100:  # If confidence is below 100, consider it as a recognized face\n",
    "            if label == 1:  # Assuming 1 corresponds to \"wmaathai\"\n",
    "                is_wmaathai = True\n",
    "                message = \"is wmaathai (front face)\"\n",
    "            else:\n",
    "                message = \"is not wmaathai (front face)\"\n",
    "        else:\n",
    "            # If confidence is 100 or higher, mark the face as unknown\n",
    "            message = \"front face is unknown (confidence too high)\"\n",
    "\n",
    "        # Display the result on the image\n",
    "        cv2.putText(test_img, message, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv2.rectangle(test_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Process each detected side face\n",
    "    for (x, y, w, h) in side_faces:\n",
    "        # Check if this face has already been processed (duplicate detection)\n",
    "        if (x, y, w, h) in processed_faces_coordinates:\n",
    "            continue  # Skip if face already processed\n",
    "\n",
    "        # Add the face coordinates to the set to avoid duplicate processing\n",
    "        processed_faces_coordinates.add((x, y, w, h))\n",
    "\n",
    "        # Extract face region from grayscale image\n",
    "        face_region = gray_img[y:y + h, x:x + w]\n",
    "\n",
    "        # Recognize the face using the trained recognizer\n",
    "        label, confidence = recognizer.predict(face_region)\n",
    "\n",
    "        # Log the label and confidence for debugging\n",
    "        print(f\"  Detected side face with label: {label}, confidence: {confidence}\")\n",
    "\n",
    "        # Adjusted confidence check for wmaathai or others\n",
    "        if confidence < 100:  # If confidence is below 100, consider it as a recognized face\n",
    "            if label == 1:  # Assuming 1 corresponds to \"wmaathai\"\n",
    "                is_wmaathai = True\n",
    "                message = \"is wmaathai (side face)\"\n",
    "            else:\n",
    "                message = \"is not wmaathai (side face)\"\n",
    "        else:\n",
    "            # If confidence is 100 or higher, mark the face as unknown\n",
    "            message = \"side face is unknown (confidence too high)\"\n",
    "\n",
    "        # Display the result on the image\n",
    "        cv2.putText(test_img, message, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv2.rectangle(test_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # If no faces were detected, output unknown\n",
    "    if len(front_faces) == 0 and len(side_faces) == 0:\n",
    "        print(f\"No faces detected in {test_image_name}\")\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct display\n",
    "    plt.title(f\"Result: {message}\")\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the test images in the test_img_dir\n",
    "for test_image_name in os.listdir(test_img_dir):\n",
    "    test_image_path = os.path.join(test_img_dir, test_image_name)\n",
    "\n",
    "    # Read the test image\n",
    "    test_img = cv2.imread(test_image_path)\n",
    "    if test_img is None:\n",
    "        print(f\"Failed to load image {test_image_path}\")\n",
    "        continue  # Skip invalid images\n",
    "\n",
    "    # Convert the test image to grayscale for face detection\n",
    "    gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using both frontal and side face classifiers\n",
    "    front_faces = front_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    side_faces = side_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Variable to track if a recognized face is found\n",
    "    is_wmaathai = False\n",
    "    print(f\"Processing image: {test_image_name}\")\n",
    "\n",
    "    # Process each detected front face\n",
    "    for (x, y, w, h) in front_faces:\n",
    "        # Check if this face has already been processed (duplicate detection)\n",
    "        if (x, y, w, h) in processed_faces_coordinates:\n",
    "            continue  # Skip if face already processed\n",
    "\n",
    "        # Add the face coordinates to the set to avoid duplicate processing\n",
    "        processed_faces_coordinates.add((x, y, w, h))\n",
    "\n",
    "        # Extract face region from grayscale image\n",
    "        face_region = gray_img[y:y + h, x:x + w]\n",
    "\n",
    "        # Recognize the face using the trained recognizer\n",
    "        label, confidence = recognizer.predict(face_region)\n",
    "\n",
    "        # Log the label and confidence for debugging\n",
    "        print(f\"  Detected front face with label: {label}, confidence: {confidence}\")\n",
    "\n",
    "        # Adjusted confidence check for wmaathai or others\n",
    "        if confidence < 100:  # If confidence is below 100, consider it as a recognized face\n",
    "            if label == 1:  # Assuming 1 corresponds to \"wmaathai\"\n",
    "                is_wmaathai = True\n",
    "                print(f\"{test_image_name} is wmaathai (front face)\")  # Correctly identified as wmaathai\n",
    "            else:\n",
    "                print(f\"{test_image_name} is not wmaathai (front face)\")  # Incorrectly identified as not wmaathai\n",
    "        else:\n",
    "            # If confidence is 100 or higher, mark the face as unknown\n",
    "            print(f\"{test_image_name} front face is unknown (confidence too high)\")  # Too high confidence, unknown\n",
    "\n",
    "    # Process each detected side face\n",
    "    for (x, y, w, h) in side_faces:\n",
    "        # Check if this face has already been processed (duplicate detection)\n",
    "        if (x, y, w, h) in processed_faces_coordinates:\n",
    "            continue  # Skip if face already processed\n",
    "\n",
    "        # Add the face coordinates to the set to avoid duplicate processing\n",
    "        processed_faces_coordinates.add((x, y, w, h))\n",
    "\n",
    "        # Extract face region from grayscale image\n",
    "        face_region = gray_img[y:y + h, x:x + w]\n",
    "\n",
    "        # Recognize the face using the trained recognizer\n",
    "        label, confidence = recognizer.predict(face_region)\n",
    "\n",
    "        # Log the label and confidence for debugging\n",
    "        print(f\"  Detected side face with label: {label}, confidence: {confidence}\")\n",
    "\n",
    "        # Adjusted confidence check for wmaathai or others\n",
    "        if confidence < 100:  # If confidence is below 100, consider it as a recognized face\n",
    "            if label == 1:  # Assuming 1 corresponds to \"wmaathai\"\n",
    "                is_wmaathai = True\n",
    "                print(f\"{test_image_name} is wmaathai (side face)\")  # Correctly identified as wmaathai\n",
    "            else:\n",
    "                print(f\"{test_image_name} is not wmaathai (side face)\")  # Incorrectly identified as not wmaathai\n",
    "        else:\n",
    "            # If confidence is 100 or higher, mark the face as unknown\n",
    "            print(f\"{test_image_name} side face is unknown (confidence too high)\")  # Too high confidence, unknown\n",
    "\n",
    "    # If no faces were detected, output unknown\n",
    "    if len(front_faces) == 0 and len(side_faces) == 0:\n",
    "        print(f\"No faces detected in {test_image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a rectangle around the face and display the label\n",
    "        # color = (0, 255, 0)  # Green color for recognized faces    \n",
    "#cv2.rectangle(test_img, (x, y), (x + w, y + h), color, 2)\n",
    "            #cv2.putText(test_img, f'Person {label}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        #else:\n",
    "            # If the confidence is high, mark the face as unknown\n",
    "            #cv2.putText(test_img, 'Unknown', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the result\n",
    "    #cv2.imshow(f\"Recognized Faces - {test_image_name}\", test_img)\n",
    "    # Save the result to a file instead of showing it\n",
    "    #cv2.imwrite(\"recognized_faces.jpg\", test_img)\n",
    "\n",
    "    #cv2.waitKey(0)  # Wait for any key to close the window\n",
    "\n",
    "#cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
