{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#images path\n",
    "img_dir = 'train_images'\n",
    "# Path to the folder containing test images\n",
    "test_img_dir = 'test_images'\n",
    "# Create a mapping from folder names to integer labels\n",
    "label_map = {'wmaathai': 1, 'others': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FaceRecognizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# initialize empty lists for training images and image-labels\n",
    "faces = []\n",
    "ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load Haar Cascade classifiers for frontal and side faces\n",
    "front_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "side_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set to track processed face coordinates (to avoid duplicates)\n",
    "processed_faces_coordinates = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\1.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\1.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\11.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\11.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\12.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\12.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\13.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\13.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\others\\14.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\others\\14.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\15.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\15.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\16.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\16.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\18.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\18.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\19.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\19.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\2.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\2.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\20.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\20.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\21.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\21.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\22.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\others\\22.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\23.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\23.jpg\n",
      "Detected 2 front face(s) and 1 side face(s) in train_images\\others\\24.jpg\n",
      "Detected 2 front face(s) and 1 side face(s) in train_images\\others\\24.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\25.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\25.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\26.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\26.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\3.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\3.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\4.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\4.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\5.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\5.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\6.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\6.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\others\\7.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\others\\7.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\8.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\others\\8.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\9.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\others\\9.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\1.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\1.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\10.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\10.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\11.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\11.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\12.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\12.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\13.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\13.jpg\n",
      "Detected 2 front face(s) and 1 side face(s) in train_images\\wmaathai\\14.jpg\n",
      "Detected 2 front face(s) and 1 side face(s) in train_images\\wmaathai\\14.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\15.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\15.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\16.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\16.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\17.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\17.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\18.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\18.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\19.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\19.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\2.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\2.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\20.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\20.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\21.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\21.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\22.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\22.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\23.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\23.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\24.jpg\n",
      "Detected 1 front face(s) and 1 side face(s) in train_images\\wmaathai\\24.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\wmaathai\\25.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\wmaathai\\25.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\26.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\26.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\27.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\27.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\wmaathai\\28.jpg\n",
      "Detected 0 front face(s) and 1 side face(s) in train_images\\wmaathai\\28.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\3.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\3.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\4.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\4.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\wmaathai\\5.jpg\n",
      "Detected 0 front face(s) and 0 side face(s) in train_images\\wmaathai\\5.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\6.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\6.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\7.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\7.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\8.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\8.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\9.jpg\n",
      "Detected 1 front face(s) and 0 side face(s) in train_images\\wmaathai\\9.jpg\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train FaceRecognizer model\n",
    "for root, dirs, files in os.walk(img_dir):\n",
    "    for filename in files:\n",
    "    \n",
    "        # Check if the file is an image (JPG, PNG, JPEG)\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(root, filename)  # Get full image path relative to root\n",
    "        \n",
    "            # Read the image\n",
    "            img = cv2.imread(image_path)\n",
    "\n",
    "            # Skip invalid images\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {image_path}\")\n",
    "                continue\n",
    "\n",
    "            # Convert the image to grayscale (Haar cascades work with grayscale images)\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect frontal faces\n",
    "            front_faces = front_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            # Detect side faces\n",
    "            side_faces = side_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            print(f\"Detected {len(front_faces)} front face(s) and {len(side_faces)} side face(s) in {image_path}\")\n",
    "\n",
    "            #skip invalid images\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # convert image to grayscale\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # load Haar CascadeClasifier and detect faces\n",
    "            # Load the pre-trained Haar cascade classifiers\n",
    "            # Detect faces using both front and side face classifiers\n",
    "            front_faces = front_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "            side_faces = side_face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            print(f\"Detected {len(front_faces)} front face(s) and {len(side_faces)} side face(s) in {image_path}\")\n",
    "\n",
    "            # Process the front faces\n",
    "            for (x, y, w, h) in front_faces:\n",
    "                # Check if this face has already been processed\n",
    "                if (x, y, w, h) in processed_faces_coordinates:\n",
    "                    continue  # Skip if face already processed\n",
    "\n",
    "                # Add the face coordinates to the set to avoid duplicate processing\n",
    "                processed_faces_coordinates.add((x, y, w, h))\n",
    "\n",
    "                # Extract face region from grayscale image\n",
    "                face = gray_img[y:y + h, x:x + w]\n",
    "                faces.append(face)  # Add the face to the list\n",
    "\n",
    "                # Get the label from the folder name\n",
    "                label = os.path.basename(root)  # Folder name as label\n",
    "                if label in label_map:\n",
    "                    ids.append(label_map[label])  # Add corresponding label\n",
    "\n",
    "                # Save the cropped front face image\n",
    "                face_img = img[y:y + h, x:x + w]  # Extract color face for saving\n",
    "                face_filename = f\"front_face_{os.path.basename(root)}_{filename}\"\n",
    "                cv2.imwrite(f'./processed_faces/{face_filename}', face_img)  # Save the front face image\n",
    "\n",
    "            # Process the side faces\n",
    "            for (x, y, w, h) in side_faces:\n",
    "                # Check if this face has already been processed\n",
    "                if (x, y, w, h) in processed_faces_coordinates:\n",
    "                    continue  # Skip if face already processed\n",
    "\n",
    "                # Add the face coordinates to the set to avoid duplicate processing\n",
    "                processed_faces_coordinates.add((x, y, w, h))\n",
    "\n",
    "                # Extract face region from grayscale image\n",
    "                face = gray_img[y:y + h, x:x + w]\n",
    "                faces.append(face)  # Add the face to the list\n",
    "\n",
    "                # Get the label from the folder name\n",
    "                label = os.path.basename(root)  # Folder name as label\n",
    "                if label in label_map:\n",
    "                    ids.append(label_map[label])  # Add corresponding label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection\n",
    "-consider if a face is not detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if faces and ids are not empty before training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Create and train the recognizer\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface\u001b[49m\u001b[38;5;241m.\u001b[39mLBPHFaceRecognizer_create()\n\u001b[0;32m      5\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39mtrain(faces, np\u001b[38;5;241m.\u001b[39marray(ids))  \u001b[38;5;66;03m# Train the recognizer with the faces and corresponding ids\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'face'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check if faces and ids are not empty before training\n",
    "if len(faces) > 0 and len(ids) > 0:\n",
    "    # Create and train the recognizer\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.train(faces, np.array(ids))  # Train the recognizer with the faces and corresponding ids\n",
    "\n",
    "    # Save the trained model\n",
    "    recognizer.save('./trained/trained_model.yml')\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "else:\n",
    "    print(\"No faces detected, model training skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(faces, np.array(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "recognizer.save('/workspaces/faceid/trained/trained_model.yml')\n",
    "print(\"Model trained and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the trained model for face recognition\n",
    "recognizer.read('/workspaces/faceid/trained/trained_model.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: 8.jpg\n",
      "Processing image: 11.jpg\n",
      "Processing image: 13.jpg\n",
      "  Detected face with label: 0, confidence: 86.99078925398025\n",
      "13.jpg is not wmaathai\n",
      "Processing image: 9.jpg\n",
      "Processing image: 16.jpg\n",
      "  Detected face with label: 0, confidence: 107.71763313927563\n",
      "16.jpg is unknown (confidence too high)\n",
      "Processing image: 5.jpg\n",
      "Processing image: 3.jpg\n",
      "  Detected face with label: 0, confidence: 67.41206249413666\n",
      "3.jpg is not wmaathai\n",
      "Processing image: 14.jpg\n",
      "  Detected face with label: 0, confidence: 103.99205966192766\n",
      "14.jpg is unknown (confidence too high)\n",
      "Processing image: 1.jpg\n",
      "Processing image: 4.jpg\n",
      "  Detected face with label: 0, confidence: 108.01684593306607\n",
      "4.jpg is unknown (confidence too high)\n",
      "Processing image: 15.jpg\n",
      "Processing image: 20.jpg\n",
      "Processing image: 7.jpg\n",
      "Processing image: 2.jpg\n",
      "Processing image: 12.jpg\n",
      "Processing image: 10.jpg\n",
      "  Detected face with label: 0, confidence: 91.24775460385793\n",
      "10.jpg is not wmaathai\n",
      "Processing image: 18.jpg\n",
      "  Detected face with label: 1, confidence: 99.74770988144303\n",
      "18.jpg is wmaathai\n",
      "Processing image: 17.jpg\n",
      "Processing image: 6.jpg\n",
      "Processing image: 19.jpg\n",
      "  Detected face with label: 0, confidence: 89.81171881151006\n",
      "19.jpg is not wmaathai\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Loop through the test images\n",
    "for test_image_name in os.listdir(test_img_dir):\n",
    "    test_image_path = os.path.join(test_img_dir, test_image_name)\n",
    "\n",
    "    test_img = cv2.imread(test_image_path)\n",
    "    if test_img is None:\n",
    "        print(f\"Failed to load image {test_image_path}\")\n",
    "        continue  # Skip invalid images\n",
    "\n",
    "    # Convert test image to grayscale for face detection\n",
    "    gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Load Haar Cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the test image\n",
    "    faces_detected = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "\n",
    "    # Variable to track if a recognized face is found\n",
    "    is_wmaathai = False\n",
    "    print(f\"Processing image: {test_image_name}\")\n",
    "\n",
    "    # Process each face detected\n",
    "    for (x, y, w, h) in faces_detected:\n",
    "        face_region = gray_img[y:y + h, x:x + w]  # Extract the face region\n",
    "\n",
    "       # Recognize the face using the trained recognizer\n",
    "        label, confidence = recognizer.predict(face_region)\n",
    "\n",
    "        # Log the label and confidence for debugging\n",
    "        print(f\"  Detected face with label: {label}, confidence: {confidence}\")\n",
    "\n",
    "        # check if value of recognition confidence is good\n",
    "        if confidence < 100:  # Low confidence means a good match\n",
    "            if label == 1:\n",
    "                is_wmaathai = True\n",
    "                print(f\"{test_image_name} is wmaathai\")\n",
    "            else:\n",
    "                print(f\"{test_image_name} is not wmaathai\")\n",
    "        else:\n",
    "            # If the confidence is too high, mark the face as unknown\n",
    "            print(f\"{test_image_name} is unknown (confidence too high)\")\n",
    "\n",
    "# If no faces were detected or recognized, output unknown\n",
    "if len(faces_detected) == 0:\n",
    "    print(f\"No faces detected in {test_image_name}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Draw a rectangle around the face and display the label\n",
    "        # color = (0, 255, 0)  # Green color for recognized faces    \n",
    "#cv2.rectangle(test_img, (x, y), (x + w, y + h), color, 2)\n",
    "            #cv2.putText(test_img, f'Person {label}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        #else:\n",
    "            # If the confidence is high, mark the face as unknown\n",
    "            #cv2.putText(test_img, 'Unknown', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the result\n",
    "    #cv2.imshow(f\"Recognized Faces - {test_image_name}\", test_img)\n",
    "    # Save the result to a file instead of showing it\n",
    "    #cv2.imwrite(\"recognized_faces.jpg\", test_img)\n",
    "\n",
    "    #cv2.waitKey(0)  # Wait for any key to close the window\n",
    "\n",
    "#cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
