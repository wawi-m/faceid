{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images path\n",
    "img_dir = '/workspaces/faceid/train_images'\n",
    "# Create a mapping from folder names to integer labels\n",
    "label_map = {'wmaathai': 1, 'others': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FaceRecognizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty lists for training images and image-labels\n",
    "faces = []\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/8.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/22.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/11.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/13.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/27.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/9.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/16.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/24.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/21.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/23.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/5.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/3.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/14.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/26.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/1.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/4.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/15.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/20.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/7.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/2.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/12.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/25.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/10.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/18.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/wmaathai/17.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/6.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/wmaathai/19.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/8.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/22.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/11.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/13.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/9.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/16.jpg\n",
      "Detected 2 face(s) in /workspaces/faceid/train_images/others/24.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/21.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/23.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/5.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/3.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/14.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/26.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/1.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/4.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/15.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/20.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/7.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/2.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/12.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/25.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/10.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/18.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/17.jpg\n",
      "Detected 1 face(s) in /workspaces/faceid/train_images/others/6.jpg\n",
      "Detected 0 face(s) in /workspaces/faceid/train_images/others/19.jpg\n"
     ]
    }
   ],
   "source": [
    "# train FaceRecognizer model\n",
    "for face_id in os.listdir(img_dir):\n",
    "    face_path = os.path.join(img_dir, face_id)\n",
    "    \n",
    "    if os.path.isdir(face_path): # Check if it's a directory (person's folder)\n",
    "        # Check if the folder name is in the label_map\n",
    "        if face_id in label_map:\n",
    "            label = label_map[face_id]\n",
    "        else:\n",
    "            continue  # Skip folders not in the label map\n",
    "\n",
    "        # process folder images\n",
    "        for img_label in os.listdir(face_path):\n",
    "            img_path = os.path.join(face_path, img_label)\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            #skip invalid images\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # convert image to grayscale\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # load Haar CascadeClasifier and detect faces\n",
    "            face_cascade = cv2.CascadeClassifier('/workspaces/faceid/haarcascades/haarcascade_frontalface_default.xml')\n",
    "            faces_detected = face_cascade.detectMultiScale(gray_img, 1.3, 5) #minSize=(40, 40)\n",
    "\n",
    "            print(f\"Detected {len(faces_detected)} face(s) in {img_path}\")\n",
    "\n",
    "            # Process each face detected\n",
    "            for (x, y, w, h) in faces_detected:\n",
    "                face = gray_img[y:y+h, x:x+w]  # Extract face region\n",
    "                faces.append(face)  # Add the face to the list\n",
    "                ids.append(int(label))  # Add the corresponding label (ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing images\n",
    "\"\"\"\n",
    "(x, y) is the top-left corner of the rectangle\n",
    "(w, h) is the width and height of the rectangle\n",
    "\"\"\"\n",
    "for (x, y, w, h) in faces_detected: # face bounding box\n",
    "    face = gray_img[y:y+h, x:x+w] # extract face from gray_img\n",
    "    faces.append(face) # add extracted face to list\n",
    "    ids.append(int(face_id))  # Label with the id (folder name)\n",
    "    #label, confidence = recognizer.predict(face_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(faces)\\nprint(ids)\\n# Check if faces and ids are empty\\nif len(faces) == 0 or len(ids) == 0:\\n    print(\"No faces detected or empty data.\")\\nelse:\\n    print(f\"Training data: {len(faces)} faces with {len(ids)} labels.\")\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(faces)\n",
    "print(ids)\n",
    "# Check if faces and ids are empty\n",
    "if len(faces) == 0 or len(ids) == 0:\n",
    "    print(\"No faces detected or empty data.\")\n",
    "else:\n",
    "    print(f\"Training data: {len(faces)} faces with {len(ids)} labels.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(faces, np.array(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "recognizer.save('trained_model.yml')\n",
    "print(\"Model trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1165184431.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[50], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    label, confidence = recognizer.predict(face_region)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Recognize the face using the pre-trained face recognizer\n",
    "                label, confidence = recognizer.predict(face_region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
